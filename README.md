# fastdeal.live

지역 기반으로 공연 티켓을 발행할 때 많은 사용자가 동시에 티켓을 구매하려 시도하는 트래픽 스파이크 상황을 재현했습니다.

이를 통해 각 단계에서 발생하는 병목 현상을 분석하고 개선하는 과정을 중점적으로 다룬 토이프로젝트입니다.

# 주요 내용

## 병목현상 개선의 프로세스

- 트래픽 스파이크 재현: 1만개의 티켓에 대해 5분간 90000명의 사용자가 동시에 요청하는 시나리오
  - 0 ~ 1분: 1초당 100명의 사용자 요청 (6,000)
  - 1 ~ 2분: 1초당 200명의 사용자 요청 (12,000)
  - 2 ~ 3분: 1초당 300명의 사용자 요청 (18,000)
  - 3 ~ 4분: 1초당 400명의 사용자 요청 (24,000)
  - 4 ~ 5분: 1초당 500명의 사용자 요청 (30,000)

- 병목현상 분석: 부하테스트중 발생하는 에러 메시지와 데이터베이스 상태 확인 등을 통해 분석

- 성능 개선
  - Next-Key-Lock vs Redis 분산락  
  - 서버 및 데이터베이스 병목현상 개선
  - 비즈니스 로직 최적화
  - 캐싱과 컨테이너화
  - 메시지큐를 통한 쓰로틀링 전략

## 그 이외의 관심사

- 읽기 쉬운 코드 지향

- 단일 책임 원칙 준수

- 테스트를 통한 코드의 안정성 확보

- 지속적인 리팩터링

# 아키텍처

![architecture](https://github.com/user-attachments/assets/adac2686-4b19-4dfa-a4ec-5b32564bfa88)


1. docker-compose와 pm2를 이용한 서버 및 인스턴스 클러스터링
2. Nginx를 통한 로드벨런싱 (round robin)
3. 캐시 Redis를 이용한 데이터베이스 부하 방지
4. 락 Redis를 이용한 분산락
5. 큐 Redis를 이용한 메시지큐 쓰로틀링

# 성능 개선

### 부하 테스트를 통한 락 전략의 효율성 비교

MySQL의 Next-Key-Lock과 Redis를 활용한 분산락 중 어느 것이 더 효율적인지에 대해 고민했습니다. 

Next-Key-Lock의 경우 인덱스와 그 다음 인덱스 사이의 갭에 락을 걸기 때문에 데이터베이스에 부하가 많이 발생할 수 있고 분산락은 짧은 주기로 락을 요청하기 때문에 서버에 부하가 많이 발생할 수 있습니다. 두 방식의 성능을 비교하기 위해 부하 테스트를 진행했고 결과는 다음과 같았습니다.

- Next-Key-Lock의 응답시간 중앙값은 79.1ms로 나타났으며, EPIPE 에러가 1403회 발생했습니다.
- 분산락의 응답시간 중앙값은 6ms로 나타났으며, EPIPE 에러가 216회 발생했습니다.

분산락이 Next-Key-Lock보다 응답속도가 빠르고 에러 빈도가 낮다는 결론을 얻었고 동시성 제어를 위해 분산락을 선택했습니다.

Next-Key-Lock 테스트 결과: https://bit.ly/4gAIpub

Redis 분산락 테스트 결과: https://bit.ly/3TEctey

### 서버 병목현상 개선

Redis 분산락을 사용했음에도 불구하고 EPIPE에러가 216회 발생했기 때문에 해당 문제를 해결해야 했습니다.

SHOW ENGINE INNODB STATUS 명령어를 실행하여 데이터베이스의 상태를 파악하고 성능에 문제가 없음을 확인했습니다. 따라서 서버에 병목현상이 있다고 판단하여 PM2를 이용해 프로세스를 5개로 확장 했습니다. 그 결과는 다음과 같았습니다.

- EPIPE 에러가 216회에서 9회로 크게 줄어들며 서버의 병목현상이 어느 정도 해결되었습니다.

서버 및 데이터베이스 병목현상 개선 테스트 결과: https://bit.ly/4d9ogIt

### 데이터베이스 병목현상 개선

"Unable to start a transaction in the given time" 에러가 새롭게 발생했기 때문에 이 문제를 해결할 필요가 있었습니다.

트랜잭션이 시간 내에 완료되지 않았다는 의미이기 때문에 데이터베이스의 상태를 확인한 결과, 서버 프로세스를 5배로 늘린 영향으로 데이터베이스의 처리 성능이 저하된 것을 확인할 수 있었습니.

로컬 MySQL의 buffer pool size는 128MB로 설정되어 있었습니다. AWS RDS t3.small 이 1GB의 buffer pool size를 가지고 있었기 때문에 이를 착안하여 buffer pool size를 1GB로 조정하였고 그 결과는 다음과 같았습니다.

- "Unable to start a transaction in the given time" 에러가 완전히 사라졌습니다.

서버 및 데이터베이스 병목현상 개선 테스트 결과: https://bit.ly/4d9ogIt

### 코드 레벨 최적화

티켓 예약이 불가능할 경우 에러를 던지는 기존 방식은 불필요한 병목현상을 유발할 수 있다고 판단했습니다. 이를 개선하기 위해 에러를 던지지 않고 성공 여부를 반환하는 방식으로 수정했습니다. 그 결과는 다음과 같았습니다.

- 응답시간 중앙값이 6ms에서 4ms로 33%개선되었습니다.

코드 레벨 최적화 테스트 결과: https://bit.ly/4d8UOCF

### 캐싱과 컨테이너화를 통한 성능 개선

앞선 개선에도 여전히 ECONNRESET 에러가 2766회 발생했습니다 이를 해결하기 위해 먼저 ECONNRESET 에러의 유력한 원인 두가지를 파악했습니다.

1. 데이터베이스 연결 작업에서 발생하는 병목현상으로 인해 서버의 성능이 저하되었다.

문제 1을 해결하기 위해 캐싱 전략을 도입했습니다. 티켓 예약 요청을 할 때 데이터베이스에 접근하기 이전에 캐시를 거치도록 했습니다. 데이터베이스에서 티켓 정보를 가져오면 해당 티켓을 "예약된 상태"로 가정하고 캐시에 저장했습니다.

1. OS에서 소켓 연결 수의 한계가 문제일 수 있다. (예: Linux의 기본 설정으로는 1024개의 동시 접속만 허용)

문제 2를 해결하기 위해 서버를 컨테이너화하여 동시 접속자의 수를 분산시켰습니다. docker-compose를 이용해 4개의 컨테이너에 서버를 띄우고 Nginx를 사용해 로드 밸런싱을 했습니다. 그 결과는 다음과 같았습니다.

- ECONNRESET 에러가 완전히 사라졌습니다.

캐싱과 컨테이너화 테스트 결과: https://bit.ly/3ZrZzE7

### 메시지큐를 통한 쓰로틀링 전략 도입

4개의 컨테이너가 한번에 연결을 시도하는 영향으로 이번에는 데이터베이스가 다룰 수 있는 커넥션의 갯수가 초과되었다는 “Too many connection” 에러가 새롭게 609회 발생했습니다.

이를 해결하기 위해 메시지큐를 통한 쓰로틀링(throttling) 전략을 도입했습니다. 메시지큐로는 Nest.js에서 공식적으로 지원하고, 특정 클라우드 서비스에 종속되지 않는 Redis BullMQ를 선택했습니다.

티켓 조회 작업과 예약 작업을 분리했습니다. 티켓 조회가 완료된 후 예약에 필요한 정보를 메시지 큐에 넣었습니다. 이후 1초에 1개의 요청만 처리하도록 설정된 프로세서에 메시지 큐가 작업을 push하여 예약 요청을 처리했습니다. 그 결과는 다음과 같았습니다.

- "Too many connections" 에러가 더 이상 발생하지 않게 되었습니다.
- 대규모 동시 요청을 매우 안정적으로 처리할 수 있게 되었습니다. (5분간 90000개의 요청 중 89999의 요청 성공)

메시지 큐 쓰로틀링 테스트 결과: https://bit.ly/3zhuLeG

### Jest를 통한 단위 테스트 작성

프로젝트를 진행하며 테스트 주도 개발(TDD)에 대해 공부했고 이를 적용하기 위해 노력했습니다. 그 결과 86.6%의 테스트 커버리지를 달성할 수 있었습니다. 테스트 코드를 많이 작성해보고 객체지향 프로그래밍(OOP)에 대해 공부하면서 "고립하여 테스트할 수 없는 코드"가 왜 객체지향적 관점에서 좋은 코드가 아닌지를 깊이 이해할 수 있었습니다. 또한 테스트를 작성하는 과정에서 예상치 못한 버그를 조기에 발견할 수 있었으며 이러한 경험은 코드의 안정성 확보에 많은 도움이 되었습니다.

TDD 기법 도입: https://hardworking-everyday.tistory.com/289

86.63%의 테스트 커버리지 달성.

![test-coverage](https://github.com/user-attachments/assets/90934019-6081-46c5-8b47-790d7029f854)
